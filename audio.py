import speech_recognition as sr
import pyaudio
import os
import tempfile
import sys
import numpy as np
from contextlib import contextmanager
from faster_whisper import WhisperModel

@contextmanager
def ignore_stderr():
    try:
        devnull = os.open(os.devnull, os.O_WRONLY)
        old_stderr = os.dup(2)
        sys.stderr.flush()
        os.dup2(devnull, 2)
        os.close(devnull)
        yield
    finally:
        os.dup2(old_stderr, 2)
        os.close(old_stderr)

class VoiceListener:
    def __init__(self, model_path_or_size="small", device="auto"):
        print(f"ğŸ”„ æ­£åœ¨åŠ è½½ Whisper æ¨¡å‹: {model_path_or_size} (Device: {device})...")
        try:
            with ignore_stderr():
                self.model = WhisperModel(model_path_or_size, device=device, compute_type="int8")
        except Exception as e:
            print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            print("âš ï¸ å°è¯•åŠ è½½é»˜è®¤ 'base' æ¨¡å‹...")
            self.model = WhisperModel("base", device=device, compute_type="int8")
        
        self.recognizer = sr.Recognizer()
        self.recognizer.energy_threshold = 300
        self.recognizer.dynamic_energy_threshold = True
        self.recognizer.pause_threshold = 0.8
        
        self.mic_index = self._find_ugreen_device_index()
        self._calibrate_noise()

    def _find_ugreen_device_index(self):
        with ignore_stderr():
            p = pyaudio.PyAudio()
            target_index = None
            keywords = ["UGREEN", "CM379", "USB Audio", "USB PnP"]
            print("ğŸ” æ­£åœ¨æ‰«æéŸ³é¢‘è®¾å¤‡...")
            try:
                info = p.get_host_api_info_by_index(0)
                numdevices = info.get('deviceCount')
                for i in range(0, numdevices):
                    device_info = p.get_device_info_by_host_api_device_index(0, i)
                    if device_info.get('maxInputChannels') > 0:
                        raw_name = device_info.get('name')
                        try:
                            name = raw_name.encode('latin-1').decode('gbk')
                        except:
                            name = raw_name
                        for k in keywords:
                            if k.lower() in name.lower():
                                target_index = i
                                print(f"âœ… é”å®šè®¾å¤‡: [{i}] {name}")
                                return target_index
            except Exception:
                pass
            finally:
                p.terminate()
        
        if target_index is None:
            print("âš ï¸ æœªæ‰¾åˆ° UGREEN è®¾å¤‡ï¼Œä½¿ç”¨ç³»ç»Ÿé»˜è®¤éº¦å…‹é£")
        return target_index

    def _calibrate_noise(self):
        if self.mic_index is not None:
            print("ğŸ”‡ æ­£åœ¨æ ¡å‡†ç¯å¢ƒå™ªéŸ³ (è¯·ä¿æŒå®‰é™ 1 ç§’)...")
            try:
                with ignore_stderr():
                    with sr.Microphone(device_index=self.mic_index) as source:
                        self.recognizer.adjust_for_ambient_noise(source, duration=1.0)
                print("âœ… æ ¡å‡†å®Œæˆ")
            except Exception as e:
                print(f"âš ï¸ æ ¡å‡†å¤±è´¥: {e}")

    def listen_and_transcribe(self):
        try:
            with ignore_stderr():
                with sr.Microphone(device_index=self.mic_index) as source:
                    print("\nğŸ‘‚ è†å¬ä¸­...", end="\r")
                    audio_data = self.recognizer.listen(source, timeout=1, phrase_time_limit=10)
                    print("âš¡ å¤„ç†ä¸­...   ", end="\r")

        except sr.WaitTimeoutError:
            return ""
        except Exception as e:
            print(f"\nâŒ å½•éŸ³é”™è¯¯: {e}")
            return ""

        temp_wav_path = None
        text_output = ""
        try:
            with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as temp_wav:
                temp_wav.write(audio_data.get_wav_data())
                temp_wav_path = temp_wav.name

            segments, info = self.model.transcribe(temp_wav_path, beam_size=5, language="zh")
            for segment in segments:
                text_output += segment.text

            if text_output:
                print(f"ğŸ“ è¯†åˆ«ç»“æœ: {text_output}")
            return text_output

        except Exception as e:
            print(f"\nâŒ è¯†åˆ«é”™è¯¯: {e}")
            return ""
        finally:
            if temp_wav_path and os.path.exists(temp_wav_path):
                os.remove(temp_wav_path)

if __name__ == "__main__":
    model_path = "/home/zz/faster-whisper-large-v3"
    
    listener = VoiceListener(model_path_or_size=model_path, device="cuda")

    print("=======================================")
    print("   è¯­éŸ³æ§åˆ¶ç³»ç»Ÿå·²å¯åŠ¨ (æé€Ÿä¼˜åŒ–ç‰ˆ)")
    print("=======================================")
    
    while True:
        try:
            result_text = listener.listen_and_transcribe()
            if result_text and len(result_text.strip()) > 0:
                pass
        except KeyboardInterrupt:
            print("\nğŸ›‘ ç¨‹åºåœæ­¢")
            break